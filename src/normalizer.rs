use once_cell::sync::Lazy;
use regex::Regex;
use serde::Deserialize;
use std::cmp::Reverse;
use std::collections::BTreeMap;
use std::fs;
use std::path::Path;

const DEFAULT_NORMALIZER_PATH: &str = "conf/normalizer.toml";
const SENTENCE_MARKER: &str = "\n<<__EBUP_SENTENCE_BOUNDARY__>>\n";

static RE_INLINE_CODE: Lazy<Regex> = Lazy::new(|| Regex::new(r"`([^`]+)`").unwrap());
static RE_MARKDOWN_LINK: Lazy<Regex> = Lazy::new(|| Regex::new(r"\[([^\]]+)\]\([^)]*\)").unwrap());
static RE_NUMERIC_BRACKET_CITE: Lazy<Regex> =
    Lazy::new(|| Regex::new(r"\[\s*\d+(?:\s*,\s*\d+)*\s*\]").unwrap());
static RE_PARENTHETICAL_NUMERIC: Lazy<Regex> =
    Lazy::new(|| Regex::new(r"\(\s*\d+(?:\s*,\s*\d+)*\s*\)").unwrap());
static RE_SQUARE_BRACKET_BLOCK: Lazy<Regex> = Lazy::new(|| Regex::new(r"\[[^\]]*\]").unwrap());
static RE_CURLY_BRACKET_BLOCK: Lazy<Regex> = Lazy::new(|| Regex::new(r"\{[^}]*\}").unwrap());
static RE_HORIZONTAL_WS: Lazy<Regex> = Lazy::new(|| Regex::new(r"[ \t\u{00A0}]+").unwrap());
static RE_SPACE_BEFORE_PUNCT: Lazy<Regex> = Lazy::new(|| Regex::new(r"\s+([,.;:!?])").unwrap());

#[derive(Debug, Clone)]
pub struct TextNormalizer {
    config: NormalizerConfig,
}

#[derive(Debug, Clone, Deserialize)]
#[serde(default)]
struct NormalizerFile {
    normalization: NormalizerConfig,
}

impl Default for NormalizerFile {
    fn default() -> Self {
        Self {
            normalization: NormalizerConfig::default(),
        }
    }
}

#[derive(Debug, Clone, Deserialize)]
#[serde(default)]
struct NormalizerConfig {
    enabled: bool,
    mode: NormalizationMode,
    collapse_whitespace: bool,
    remove_space_before_punctuation: bool,
    strip_inline_code: bool,
    strip_markdown_links: bool,
    drop_numeric_bracket_citations: bool,
    drop_parenthetical_numeric_citations: bool,
    drop_square_bracket_text: bool,
    drop_curly_brace_text: bool,
    min_sentence_chars: usize,
    require_alphanumeric: bool,
    replacements: BTreeMap<String, String>,
    drop_tokens: Vec<String>,
    acronyms: AcronymConfig,
    pronunciation: PronunciationConfig,
}

impl Default for NormalizerConfig {
    fn default() -> Self {
        let mut replacements = BTreeMap::new();
        replacements.insert("#".to_string(), " ".to_string());

        Self {
            enabled: true,
            mode: NormalizationMode::Page,
            collapse_whitespace: true,
            remove_space_before_punctuation: true,
            strip_inline_code: true,
            strip_markdown_links: true,
            drop_numeric_bracket_citations: true,
            drop_parenthetical_numeric_citations: true,
            drop_square_bracket_text: true,
            drop_curly_brace_text: true,
            min_sentence_chars: 2,
            require_alphanumeric: true,
            replacements,
            drop_tokens: Vec::new(),
            acronyms: AcronymConfig::default(),
            pronunciation: PronunciationConfig::default(),
        }
    }
}

#[derive(Debug, Clone, Copy, Deserialize, PartialEq, Eq, Default)]
#[serde(rename_all = "kebab-case")]
enum NormalizationMode {
    #[default]
    Page,
    Sentence,
}

#[derive(Debug, Clone, Deserialize)]
#[serde(default)]
struct AcronymConfig {
    enabled: bool,
    tokens: Vec<String>,
    letter_separator: String,
    digit_separator: String,
    letter_sounds: BTreeMap<String, String>,
}

impl Default for AcronymConfig {
    fn default() -> Self {
        Self {
            enabled: true,
            tokens: vec![
                "CSS".to_string(),
                "HTML".to_string(),
                "HTTP".to_string(),
                "HTTPS".to_string(),
                "URL".to_string(),
                "API".to_string(),
                "CPU".to_string(),
                "GPU".to_string(),
                "JSON".to_string(),
                "SQL".to_string(),
                "XML".to_string(),
                "TTS".to_string(),
                "XTTS".to_string(),
                "LLM".to_string(),
            ],
            letter_separator: " ".to_string(),
            digit_separator: " point ".to_string(),
            letter_sounds: default_letter_sounds(),
        }
    }
}

#[derive(Debug, Clone, Deserialize)]
#[serde(default)]
struct PronunciationConfig {
    year_mode: YearMode,
    number_separator: String,
    insert_and: bool,
    enable_brand_map: bool,
    brand_map: BTreeMap<String, String>,
}

impl Default for PronunciationConfig {
    fn default() -> Self {
        let mut brand_map = BTreeMap::new();
        brand_map.insert("MySQL".to_string(), "My S Q L".to_string());
        brand_map.insert("Mysql".to_string(), "My S Q L".to_string());
        brand_map.insert("SQLite".to_string(), "S Q Lite".to_string());
        brand_map.insert("SQLITE".to_string(), "S Q Lite".to_string());
        brand_map.insert("PostCSS".to_string(), "Post C S S".to_string());

        Self {
            year_mode: YearMode::American,
            number_separator: " ".to_string(),
            insert_and: false,
            enable_brand_map: true,
            brand_map,
        }
    }
}

#[derive(Debug, Clone, Copy, Deserialize, PartialEq, Eq, Default)]
#[serde(rename_all = "kebab-case")]
enum YearMode {
    #[default]
    American,
    None,
}

#[derive(Debug, Clone)]
pub struct PageNormalization {
    pub audio_sentences: Vec<String>,
    pub display_to_audio: Vec<Option<usize>>,
    pub audio_to_display: Vec<usize>,
}

impl TextNormalizer {
    pub fn load_default() -> Self {
        Self::load(Path::new(DEFAULT_NORMALIZER_PATH))
    }

    pub fn load(path: &Path) -> Self {
        match fs::read_to_string(path) {
            Ok(contents) => match toml::from_str::<NormalizerFile>(&contents) {
                Ok(file) => {
                    tracing::info!(path = %path.display(), "Loaded text normalizer config");
                    Self {
                        config: file.normalization,
                    }
                }
                Err(err) => {
                    tracing::warn!(path = %path.display(), "Invalid normalizer config TOML: {err}");
                    Self::default()
                }
            },
            Err(err) => {
                tracing::warn!(path = %path.display(), "Falling back to default normalizer config: {err}");
                Self::default()
            }
        }
    }

    pub fn plan_page(&self, display_sentences: &[String]) -> PageNormalization {
        if display_sentences.is_empty() {
            return PageNormalization {
                audio_sentences: Vec::new(),
                display_to_audio: Vec::new(),
                audio_to_display: Vec::new(),
            };
        }

        if !self.config.enabled {
            let audio_sentences = display_sentences.to_vec();
            let display_to_audio = (0..display_sentences.len()).map(Some).collect();
            let audio_to_display = (0..display_sentences.len()).collect();
            return PageNormalization {
                audio_sentences,
                display_to_audio,
                audio_to_display,
            };
        }

        let cleaned_sentences = match self.config.mode {
            NormalizationMode::Page => self.normalize_page_mode(display_sentences),
            NormalizationMode::Sentence => display_sentences
                .iter()
                .map(|sentence| self.clean_text_core(sentence))
                .collect(),
        };

        let mut audio_sentences = Vec::with_capacity(cleaned_sentences.len());
        let mut display_to_audio = vec![None; cleaned_sentences.len()];
        let mut audio_to_display = Vec::new();

        for (display_idx, sentence) in cleaned_sentences.into_iter().enumerate() {
            if let Some(cleaned) = self.finalize_sentence(&sentence) {
                let audio_idx = audio_sentences.len();
                audio_sentences.push(cleaned);
                display_to_audio[display_idx] = Some(audio_idx);
                audio_to_display.push(display_idx);
            }
        }

        PageNormalization {
            audio_sentences,
            display_to_audio,
            audio_to_display,
        }
    }

    fn normalize_page_mode(&self, display_sentences: &[String]) -> Vec<String> {
        let joined = display_sentences.join(SENTENCE_MARKER);
        let cleaned = self.clean_text_core(&joined);
        let split: Vec<String> = cleaned
            .split(SENTENCE_MARKER)
            .map(|part| part.to_string())
            .collect();

        if split.len() == display_sentences.len() {
            split
        } else {
            tracing::debug!(
                expected = display_sentences.len(),
                actual = split.len(),
                "Normalizer marker split mismatch; falling back to sentence mode"
            );
            display_sentences
                .iter()
                .map(|sentence| self.clean_text_core(sentence))
                .collect()
        }
    }

    fn clean_text_core(&self, input: &str) -> String {
        let mut text = input.to_string();

        if self.config.strip_markdown_links {
            text = RE_MARKDOWN_LINK.replace_all(&text, "$1").to_string();
        }

        if self.config.strip_inline_code {
            text = RE_INLINE_CODE.replace_all(&text, "$1").to_string();
        }

        if self.config.drop_numeric_bracket_citations {
            text = RE_NUMERIC_BRACKET_CITE.replace_all(&text, " ").to_string();
        }

        if self.config.drop_parenthetical_numeric_citations {
            text = RE_PARENTHETICAL_NUMERIC.replace_all(&text, " ").to_string();
        }

        if self.config.drop_square_bracket_text {
            text = RE_SQUARE_BRACKET_BLOCK.replace_all(&text, " ").to_string();
        }

        if self.config.drop_curly_brace_text {
            text = RE_CURLY_BRACKET_BLOCK.replace_all(&text, " ").to_string();
        }

        if !self.config.replacements.is_empty() {
            let mut entries: Vec<_> = self.config.replacements.iter().collect();
            entries.sort_by_key(|(from, _)| Reverse(from.len()));
            for (from, to) in entries {
                text = text.replace(from.as_str(), to.as_str());
            }
        }

        if !self.config.drop_tokens.is_empty() {
            for token in &self.config.drop_tokens {
                if !token.is_empty() {
                    text = text.replace(token, " ");
                }
            }
        }

        if self.config.pronunciation.enable_brand_map
            && !self.config.pronunciation.brand_map.is_empty()
        {
            text = apply_brand_map(&text, &self.config.pronunciation.brand_map);
        }

        if self.config.pronunciation.year_mode != YearMode::None {
            text = apply_year_pronunciation(&text, &self.config.pronunciation);
        }

        if self.config.acronyms.enabled && !self.config.acronyms.tokens.is_empty() {
            text = apply_acronym_expansion(&text, &self.config.acronyms);
        }

        if self.config.collapse_whitespace {
            text = RE_HORIZONTAL_WS.replace_all(&text, " ").to_string();
        }

        if self.config.remove_space_before_punctuation {
            text = RE_SPACE_BEFORE_PUNCT.replace_all(&text, "$1").to_string();
        }

        text.trim().to_string()
    }

    fn finalize_sentence(&self, sentence: &str) -> Option<String> {
        let trimmed = sentence.trim();
        if trimmed.is_empty() {
            return None;
        }

        if self.config.require_alphanumeric && !trimmed.chars().any(|ch| ch.is_alphanumeric()) {
            return None;
        }

        if trimmed.chars().count() < self.config.min_sentence_chars.max(1) {
            return None;
        }

        Some(trimmed.to_string())
    }
}

impl Default for TextNormalizer {
    fn default() -> Self {
        Self {
            config: NormalizerConfig::default(),
        }
    }
}

fn default_letter_sounds() -> BTreeMap<String, String> {
    let mut map = BTreeMap::new();
    for ch in 'A'..='Z' {
        map.insert(ch.to_string(), ch.to_string());
    }
    for (digit, word) in [
        ('0', "zero"),
        ('1', "one"),
        ('2', "two"),
        ('3', "three"),
        ('4', "four"),
        ('5', "five"),
        ('6', "six"),
        ('7', "seven"),
        ('8', "eight"),
        ('9', "nine"),
    ] {
        map.insert(digit.to_string(), word.to_string());
    }
    map
}

fn apply_brand_map(text: &str, brand_map: &BTreeMap<String, String>) -> String {
    let mut out = text.to_string();
    let mut entries: Vec<_> = brand_map.iter().collect();
    entries.sort_by_key(|(token, _)| Reverse(token.len()));

    for (token, replacement) in entries {
        let pattern = Regex::new(&format!(r"(?i)\b{}\b", regex::escape(token))).unwrap();
        out = pattern.replace_all(&out, replacement.as_str()).to_string();
    }

    out
}

fn apply_year_pronunciation(text: &str, cfg: &PronunciationConfig) -> String {
    let re = Regex::new(r"\b(1\d{3}|20\d{2})\b").unwrap();
    re.replace_all(text, |caps: &regex::Captures| {
        let year = caps[1].parse::<usize>().unwrap_or(0);
        year_to_words(year, cfg)
    })
    .to_string()
}

fn year_to_words(year: usize, cfg: &PronunciationConfig) -> String {
    if year < 1000 || year > 2099 {
        return year.to_string();
    }

    let ones = [
        "", "one", "two", "three", "four", "five", "six", "seven", "eight", "nine",
    ];
    let teens = [
        "ten",
        "eleven",
        "twelve",
        "thirteen",
        "fourteen",
        "fifteen",
        "sixteen",
        "seventeen",
        "eighteen",
        "nineteen",
    ];
    let tens = [
        "", "", "twenty", "thirty", "forty", "fifty", "sixty", "seventy", "eighty", "ninety",
    ];

    let thousands = year / 1000;
    let hundreds = (year / 100) % 10;
    let remainder = year % 100;

    let mut parts = Vec::new();
    if thousands > 0 {
        parts.push(format!("{} thousand", ones[thousands]));
    }
    if hundreds > 0 {
        parts.push(format!("{} hundred", ones[hundreds]));
    }

    if remainder > 0 {
        let remainder_str = if remainder < 10 {
            ones[remainder].to_string()
        } else if remainder < 20 {
            teens[remainder - 10].to_string()
        } else {
            let mut s = tens[remainder / 10].to_string();
            if remainder % 10 > 0 {
                s.push(' ');
                s.push_str(ones[remainder % 10]);
            }
            s
        };

        if hundreds > 0 && cfg.insert_and {
            parts.push(format!("and {remainder_str}"));
        } else {
            parts.push(remainder_str);
        }
    }

    parts.join(&cfg.number_separator)
}

fn apply_acronym_expansion(text: &str, cfg: &AcronymConfig) -> String {
    let mut out = text.to_string();

    for token in &cfg.tokens {
        let pattern = format!(
            r"(?i)\b{}(?P<digits>\d+(?:\.\d+)*)?\b",
            regex::escape(token)
        );
        let re = Regex::new(&pattern).unwrap();
        out = re
            .replace_all(&out, |caps: &regex::Captures| {
                let letters = caps[0]
                    .chars()
                    .filter(|ch| ch.is_ascii_alphabetic())
                    .map(|ch| {
                        let key = ch.to_ascii_uppercase().to_string();
                        cfg.letter_sounds.get(&key).cloned().unwrap_or_else(|| key)
                    })
                    .collect::<Vec<_>>();

                let mut spelled = letters.join(&cfg.letter_separator);
                if let Some(digits) = caps.name("digits") {
                    let digits = digits.as_str().trim();
                    if !digits.is_empty() {
                        let spoken_digits = digits
                            .split('.')
                            .map(|group| {
                                group
                                    .chars()
                                    .filter(|ch| ch.is_ascii_digit())
                                    .map(|ch| {
                                        cfg.letter_sounds
                                            .get(&ch.to_string())
                                            .cloned()
                                            .unwrap_or_else(|| ch.to_string())
                                    })
                                    .collect::<Vec<_>>()
                                    .join(&cfg.letter_separator)
                            })
                            .filter(|group| !group.is_empty())
                            .collect::<Vec<_>>()
                            .join(&cfg.digit_separator);

                        if !spoken_digits.is_empty() {
                            if !spelled.is_empty() {
                                spelled.push(' ');
                            }
                            spelled.push_str(&spoken_digits);
                        }
                    }
                }

                if spelled.is_empty() {
                    caps[0].to_string()
                } else {
                    spelled
                }
            })
            .to_string();
    }

    out
}
